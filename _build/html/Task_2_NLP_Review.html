
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Natural language processing Task &#8212; Predicting Football Match Outcomes using Machine Learning and Human Experts input</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Model Evaluation" href="Model_Evaluation.html" />
    <link rel="prev" title="Data collection" href="Theguardian_scraper.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Predicting Football Match Outcomes using Machine Learning and Human Experts input</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Intro.html">
   A multi-task learning approach to predict the outcome of a football game using human experts input
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Literature_review.html">
   Literature review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Theguardian_scraper.html">
   Data collection
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Natural language processing Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Model_Evaluation.html">
   Model Evaluation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/Task_2_NLP_Review.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FTask_2_NLP_Review.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/Task_2_NLP_Review.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#information-extraction">
   Information extraction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#named-entity-recognition-ner">
     Named Entity Recognition (NER)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lower-casing">
     Lower Casing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tokenization">
     Tokenization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#punctuation-marks-removal">
     Punctuation Marks Removal
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stop-words-removal">
     Stop Words Removal
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lemmatization">
     Lemmatization
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#allocation-of-text-context">
   Allocation of text context
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-vectorisation">
   Text vectorisation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prediction">
   Prediction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#proof-of-concept">
   Proof of concept
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Information Extraction
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Named Entity Recognition (NER)
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#example">
         Example
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#train-a-model-to-detect-custom-entities">
         Train a model to detect custom entities
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#entity-ruler">
       Entity ruler
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#get-the-names-of-the-coaches">
       Get the names of the coaches
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#previews-preprocessing">
       Previews Preprocessing
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id3">
         Example
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-allocation">
     Text allocation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Text vectorisation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     Prediction
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#get-target-values">
       Get target values
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-proportions-of-the-results">
       The proportions of the results
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#split-data-into-train-and-test-dataset">
       Split data into train and test dataset
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#random-forest-classifier">
       Random Forest Classifier
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reference">
   Reference
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Natural language processing Task</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#information-extraction">
   Information extraction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#named-entity-recognition-ner">
     Named Entity Recognition (NER)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lower-casing">
     Lower Casing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tokenization">
     Tokenization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#punctuation-marks-removal">
     Punctuation Marks Removal
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stop-words-removal">
     Stop Words Removal
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lemmatization">
     Lemmatization
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#allocation-of-text-context">
   Allocation of text context
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-vectorisation">
   Text vectorisation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prediction">
   Prediction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#proof-of-concept">
   Proof of concept
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Information Extraction
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Named Entity Recognition (NER)
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#example">
         Example
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#train-a-model-to-detect-custom-entities">
         Train a model to detect custom entities
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#entity-ruler">
       Entity ruler
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#get-the-names-of-the-coaches">
       Get the names of the coaches
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#previews-preprocessing">
       Previews Preprocessing
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id3">
         Example
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-allocation">
     Text allocation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Text vectorisation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     Prediction
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#get-target-values">
       Get target values
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-proportions-of-the-results">
       The proportions of the results
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#split-data-into-train-and-test-dataset">
       Split data into train and test dataset
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#random-forest-classifier">
       Random Forest Classifier
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reference">
   Reference
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="natural-language-processing-task">
<h1>Natural language processing Task<a class="headerlink" href="#natural-language-processing-task" title="Permalink to this headline">¶</a></h1>
<p>To fill the gap between human communication and machine understanding, NLP (Natural Language Processing) contains a range of sciences, including computer science and computational linguistics. It is significant because it aids in the resolution of linguistic ambiguity and provides quantitative structure to data for a variety of real - world applications such as speech recognition and text analytics.
<br>After completing our first task, which was to extract previews from the Guardian website, we began our second task, which was to reproduce the results of the <cite id="cfvjb"><a href="#zotero|11983139/J4T53NKQ">(Beal et al., 2021)</a></cite> article by processing and analyzing the texts that we had extracted.
The article’s authors proceeded as follows:</p>
<ul class="simple">
<li><p><b> Information extraction</b>: they extracted the main features of each sentence in the article’s text.</p></li>
<li><p><b>Allocation of Text Context</b>: each sentence is assigned to a team.</p></li>
<li><p><b>Text Vectorisation</b>: they converted the sentences into vectors using a Count Vectorizer technique to have a numerical representation of the words in a sentence.</p></li>
<li><p><b>Prediction</b>: Once the feature set for each game is formed, they trained a Random Forest model using historic</p></li>
</ul>
<div class="section" id="information-extraction">
<h2>Information extraction<a class="headerlink" href="#information-extraction" title="Permalink to this headline">¶</a></h2>
<p>Information Extraction (IE) is the process of extracting meaningful information from unstructured text data and presenting it in a structured format.
<br>We can use information extraction to retrieve pre-defined information, such as a person’s name, the location of an organisation, or the identification of a relationship between entities, and save it in a structured format, such as a database. This technique is called the Named Entity Recognition.</p>
<div class="section" id="named-entity-recognition-ner">
<h3>Named Entity Recognition (NER)<a class="headerlink" href="#named-entity-recognition-ner" title="Permalink to this headline">¶</a></h3>
<p>The task of identifying and categorizing key information in text is known as Named Entity Recognition (NER). It is also known as entity extraction or identification. Each detected entity is assigned to a predefined category.
An NER model, for example, may detect the word “Mark” in a text and classify it as a “Person.”</p>
<p><br>However, before the IE step, Data Preprocessing is required for any Machine Learning model. The model’s performance is heavily influenced by how well the raw data has been cleaned and preprocessed. Similarly, in the case of NLP, the first step is text processing.
<br>The various preprocessing steps are as follows:</p>
<ul class="simple">
<li><p>Lower Casing</p></li>
<li><p>Tokenization</p></li>
<li><p>Punctuation Mark Removal</p></li>
<li><p>Stop Word Removal</p></li>
<li><p>Lemmatization</p></li>
</ul>
</div>
<div class="section" id="lower-casing">
<h3>Lower Casing<a class="headerlink" href="#lower-casing" title="Permalink to this headline">¶</a></h3>
<p>When we get text input, such as a paragraph, we find both lower and upper case words.On the other hand, The computer considers the identical words typed in various cases to be separate entities.For example, The computer, considers ‘football’ and ‘FOOTBALL’ to be two distinct terms, despite the fact that they both imply the same thing.We must change all of the words to lower case in order to solve this problem. The text will be more consistent as a result of this.</p>
</div>
<div class="section" id="tokenization">
<h3>Tokenization<a class="headerlink" href="#tokenization" title="Permalink to this headline">¶</a></h3>
<p>Tokenization is the next text preparation step. Tokenization is the act of dividing a paragraph into smaller parts like sentences or words. Each unit is then treated as a separate token. Tokenization’s primary premise is to attempt to grasp the meaning of the text by studying the smaller components or tokens that comprise the paragraph.</p>
</div>
<div class="section" id="punctuation-marks-removal">
<h3>Punctuation Marks Removal<a class="headerlink" href="#punctuation-marks-removal" title="Permalink to this headline">¶</a></h3>
<p>Depending on the scenario, we may need to delete or keep punctuation from the text.</p>
</div>
<div class="section" id="stop-words-removal">
<h3>Stop Words Removal<a class="headerlink" href="#stop-words-removal" title="Permalink to this headline">¶</a></h3>
<p>Stop words are words that appear often in any language but do not contribute much sense to sentences. These are frequent terms that are part of any language’s grammar. Stop words are unique to each language.For example, Stop words in English include “the,” “he,” “he,” “his,” “her,” “herself,” and so on. By removing stop words, we may successfully lower the dimensionality of our text collection without sacrificing any important information.</p>
</div>
<div class="section" id="lemmatization">
<h3>Lemmatization<a class="headerlink" href="#lemmatization" title="Permalink to this headline">¶</a></h3>
<p>Because there are many words in a text that have the same root and meaning, it is evident to normalise the text by applying the lemmatization technique, which helps to reduce a given term to its root word.</p>
</div>
</div>
<div class="section" id="allocation-of-text-context">
<h2>Allocation of text context<a class="headerlink" href="#allocation-of-text-context" title="Permalink to this headline">¶</a></h2>
<p>This section consists of assigning each sentence to the appropriate team. In a preview, for example, the journalist may discuss squad A or team B. As a result, we will have three columns: one for sentences about team A, another for sentences about team B, and a third for sentences about both teams at the same time.</p>
</div>
<div class="section" id="text-vectorisation">
<h2>Text vectorisation<a class="headerlink" href="#text-vectorisation" title="Permalink to this headline">¶</a></h2>
<p>When the text processing and allocation phases are completed, it is time to begin the modeling phase.
<br>However, our model will not be able to understand these raw texts, so we must convert them into vectors, which are digital representations of these character strings.Here, the goal is to extract textual features so that the model can learn.
<br>Among the vectorization techniques, we highlight the bag of words: it is a very simple technique that calculates the vectors of a text based on the frequency of vocabulary words.
It is simple to interpret and only refers to the frequency of vocabulary words in a given document.
<br>As a result, articles, prepositions, and conjunctions that do not contribute much to meaning are just as important as adjectives or verbs.
<br>An example for the count vectorization technique:</p>
<p><img alt="title" src="_images/countvector.png" /></p>
<p><br>In addition, there are other techniques that, in general, work better in machine learning models to address this issue such as TF-IDF: term frequency-inverse document frequency.
<br>The idea behind the TF-IDF approach is that words that appear less frequently in all documents but more frequently in individual documents contribute more to classification.
these terms can be calculated as follows:</p>
<p><img alt="title" src="_images/tfidf.png" /></p>
</div>
<div class="section" id="prediction">
<h2>Prediction<a class="headerlink" href="#prediction" title="Permalink to this headline">¶</a></h2>
<p>There are various methods in machine learning for dealing with classification or regression problems that are highly fascinating to try.
<br>In this work, we will use a random forest classifier that takes vectorized texts as input to predict the outcomes of football matches(Home win, Away win, Draw).</p>
</div>
<div class="section" id="proof-of-concept">
<h2>Proof of concept<a class="headerlink" href="#proof-of-concept" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>Information Extraction<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id2">
<h4>Named Entity Recognition (NER)<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<p>In our case, identifying the names of the teams in the previews is a critical task that will allow us to extract the main features in our text.
<br>This operation is not possible with the standard spacy NER because of errors in entity detection; spacy can consider a team name to be a person and vice versa.
<br>To address this issue, we decided to build a model that will allow us to detect our own entities.</p>
<div class="section" id="example">
<h5>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h5>
<p><img alt="title" src="_images/ner.png" /></p>
<p><img alt="title" src="_images/ner2.png" /></p>
</div>
<div class="section" id="train-a-model-to-detect-custom-entities">
<h5>Train a model to detect custom entities<a class="headerlink" href="#train-a-model-to-detect-custom-entities" title="Permalink to this headline">¶</a></h5>
<p><img alt="title" src="_images/ner3.png" />
<img alt="title" src="_images/ner4.png" /></p>
<p>We test again:</p>
<p><img alt="title" src="_images/ner5.png" /></p>
</div>
</div>
<div class="section" id="entity-ruler">
<h4>Entity ruler<a class="headerlink" href="#entity-ruler" title="Permalink to this headline">¶</a></h4>
<p>Using token-based rules or exact phrase matches, the entity ruler allows us to add spans to the Doc entities. It can be used in conjunction with the statistical EntityRecognizer to improve accuracy, or it can be used on its own to implement a rule-based entity recognition system.
<br>We took advantage of the dataset that we have which contains the teams and their different names.
In this sense we have linked each name or nickname of a team to its main entity</p>
<p><img alt="title" src="_images/ner6.png" /></p>
<p>For example the nickname Spurs is now detectable in the text that is linked to the Tottenham Hotspur entity</p>
<p><img alt="title" src="_images/ner7.png" /></p>
</div>
<div class="section" id="get-the-names-of-the-coaches">
<h4>Get the names of the coaches<a class="headerlink" href="#get-the-names-of-the-coaches" title="Permalink to this headline">¶</a></h4>
<p>We also noticed that in most of the previews, we find the names of the managers but not the names of the teams,
so to ensure the extraction of information, we used a database that we have that contains a history of managers for each team.<br>As a result, it is now easier to identify the section of the text that refers to one of the two teams.</p>
<p>Example of the dataset:</p>
<p><img alt="title" src="_images/coach1.png" /></p>
<p>The final output: for each preview, we have the coaches of each team.</p>
<p><img alt="title" src="_images/coach2.png" /></p>
</div>
<div class="section" id="previews-preprocessing">
<h4>Previews Preprocessing<a class="headerlink" href="#previews-preprocessing" title="Permalink to this headline">¶</a></h4>
<p>First of all, beginning with the tokenization step, which is the task of chopping up texts into pieces in order to remove stop words such as (the,a,an,so,what..). We also removed all punctuation because it isn’t important in the text, and then we used a lemmatization technique that allows for lexical processing, such as (runs, running,ran) returns run.</p>
<div class="section" id="id3">
<h5>Example<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h5>
<p><img alt="title" src="_images/text1.png" /></p>
<p><img alt="title" src="_images/token.png" /></p>
<p>We continue our normalization and move on to the next step, which is detecting the names of the two teams, the names of the coaches, and changing their names by hometeam, awayteam, homecoach, and awaycoach.The reason for this is so that our model’s predictions can generalize.
<br>We noticed that the words ‘hosts,’ ‘home side,’ and ‘visitors,’ which refer to the home team and away team, are frequently used in the previews, and they have been changed.</p>
<p>We take the same example:</p>
<p><img alt="title" src="_images/text2.png" /></p>
<p>Preview after cleanning:</p>
<p><img alt="title" src="_images/preview.png" /></p>
<p>Preview after normalization:</p>
<p><img alt="title" src="_images/preview2.png" /></p>
</div>
</div>
</div>
<div class="section" id="text-allocation">
<h3>Text allocation<a class="headerlink" href="#text-allocation" title="Permalink to this headline">¶</a></h3>
<p>After having cleaned and normalized the texts, obtaining the target values of each preview, we move on to the next step which consists of decomposing the texts of each preview and allocating each sentence to the corresponding team.
for some previews, there are sentences that talk about the two teams, that’s why we created 3 new columns for our dataset:</p>
<ul class="simple">
<li><p>homeTeamText: this is the text that talks about home team</p></li>
<li><p>awayTeamText: this is the text that talks about away team</p></li>
<li><p>bothteamText: this is the text that speaks of the two teams</p></li>
</ul>
<p><br> Here we have worked with the pre-built entities to detect teams names in the text, but as we said , this is not always reliable that’s why we have employed the teams and the coaches dataset which contains their different names to search it in each sentence.
<br> If the home team name or the home coach name are included in the sentence , so it’s very likely that it’s related to the home team and it’s the same scenario for away team.
<br> We also noticed that the words ‘hosts’,‘home side’,’home crowd’,’these sides’,’these teams’,’both teams’,’two sides’ and ‘visitors’ which refer to the home team and away team, are frequently used in the previews, so we changed these terms by ‘bothteam’ to detect sentences.</p>
<p><img alt="title" src="_images/vecttext.png" /></p>
</div>
<div class="section" id="id4">
<h3>Text vectorisation<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>It should be emphasized that for this work, we will utilize the count vectorizer approach to vectorize the preview texts.
<br>This function comprises certain hyperparameters that must be fixed and find the best combinations in order to increase the quality of the vectors.
<br>Among these hyperparameters, we can find:</p>
<ul class="simple">
<li><p>stop_words: CountVectorizer provides a predefined set of stop words; in our case, we can specify ‘english.’</p></li>
<li><p>ngram_range: the number of word combinations to consider, for example (1,1) takes only tokens, whereas (1,2) specifies that we want to consider both unigrams (single words) and bigrams (combination of 2 words)</p></li>
<li><p>min_df:stands for minimum document frequency; it disregards words with a document frequency that is strictly lower than the specified threshold.</p></li>
</ul>
</div>
<div class="section" id="id5">
<h3>Prediction<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<div class="section" id="get-target-values">
<h4>Get target values<a class="headerlink" href="#get-target-values" title="Permalink to this headline">¶</a></h4>
<p>To enable our model to train and make predictions, we must first provide the target values (the outputs of the matches).
<br>We have set two target values:</p>
<ul class="simple">
<li><p>The outcome of a match: home win, away win, draw</p></li>
<li><p>The goal difference: the difference in goals scored</p></li>
</ul>
<p><img alt="title" src="_images/final_data.png" /></p>
</div>
<div class="section" id="the-proportions-of-the-results">
<h4>The proportions of the results<a class="headerlink" href="#the-proportions-of-the-results" title="Permalink to this headline">¶</a></h4>
<p>It is worth noting that the class distribution of English Premier League games that we have from 2009 to 2022 is 45% home wins, draws 25% and away wins 30%.</p>
<p><img alt="title" src="_images/stats.png" /></p>
</div>
<div class="section" id="split-data-into-train-and-test-dataset">
<h4>Split data into train and test dataset<a class="headerlink" href="#split-data-into-train-and-test-dataset" title="Permalink to this headline">¶</a></h4>
<p>Before setting up a machine learning model, we must divide our data into train and test data. the train dataset is used to train the machine learning model and the test dataset is to assess the fit, which is data that the model has never seen before. To accomplish this, we will take data from 2009 to 2018 for the train data and the rest from the 2019 until now for the test dataset. The reason of not applying a shuffle is to avoid distorting the temporal order of the matches.</p>
</div>
<div class="section" id="random-forest-classifier">
<h4>Random Forest Classifier<a class="headerlink" href="#random-forest-classifier" title="Permalink to this headline">¶</a></h4>
<p>A random forest’s fundamental notion is to aggregate a large number of individual decision trees into a single model that function as an ensemble. All individual tree projections are pooled, and the class with the highest votes becomes our model’s prediction.
We have to note that each tree uses slightly different subsets of data, which means they may not contain the same columns and rows
<br>In addition, we can experiment with several hyperparameters in the Random forest classifier to increase model performance, such as:</p>
<ul class="simple">
<li><p>n_estimators: the number of trees that the classifier will consider.</p></li>
<li><p>max_depth: the longest path from the root node to the leaf node.</p></li>
<li><p>min_sample_split: the minimal amount of observations required to split any given node.</p></li>
<li><p>Criterion: a function that determines how good a split is. we can experiment with (gini,entropy) values.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<!-- BIBLIOGRAPHY START -->
<div class="csl-bib-body">
  <div class="csl-entry"><i id="zotero|11983139/J4T53NKQ"></i>Beal, R., Middleton, S. E., Norman, T. J., &#38; Ramchurn, S. D. (2021). Combining Machine Learning and Human Experts to Predict Match Outcomes in Football: A Baseline Model. <i>Proceedings of the AAAI Conference on Artificial Intelligence, 35(17), 15447-15451</i>.  https://ojs.aaai.org/index.php/AAAI/article/view/17815</div>
</div>
<!-- BIBLIOGRAPHY END --></div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Theguardian_scraper.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Data collection</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Model_Evaluation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Model Evaluation</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Meher Kharbachi<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>